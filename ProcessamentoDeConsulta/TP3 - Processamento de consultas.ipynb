{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto você irá implementar o processamento de consultas. Nela, você utilizará o índice para retornar uma coleção ordenada e avaliação de algumas consultas selecionadas. Para isso, vocês deverão implementar alguns métodos das seguintes classes.\n",
    "\n",
    "- `IndexPreComputedVals`: Em alguns modelos, há a necessidade de processar alguns valores para que, no momento da execução da consulta, seja retornado de forma mais rápida. Esta classe analisa o índice e armazena informações necessárias para o calculo de cada tipo de modelagem;\n",
    "- `RankingModel`: Classe abstrata para a criação dos modelos. Ele possui o método `get_ordered_docs` a ser implementado por suas subclasses;\n",
    "- `BooleanRankingModel` Classe que retorna um resultado de consulta por meio do [modelo booleano](https://docs.google.com/presentation/d/1V62ll_IXRrsp6TYUHjx_T4jIyIc1ZVJYoOSwsxObybE/edit?usp=sharing)\n",
    "- `VectorRankingModel`: Classe que retorna um resultado de consulta por meio do [modelo vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing)\n",
    "- `QueryRunner`: Classe principal encarregada de obter a consulta e retornar os resultados;\n",
    "\n",
    "\n",
    "Este trabalho depende do código do indice (pacote `index`). Assim, você deve adicioná-o apropriadamente para dar continuidade ao projeto. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem Booleana e Vetorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 1 - Modelagem Booleana**: A abordagem booleana neste trabalho é simplificada. O modelo recebe o atributo `operator` que é uma instancia do [Enum](https://docs.python.org/3.4/library/enum.html) Operator. Caso o operador seja AND, será feito a operacao de interseção entre todos os documentos contidos ocorrencias de palavras, caso contrario, sendo OR, será feito a união. Exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.index.structure import TermOccurrence\n",
    "map_ocorrencias = {\"saturno\":[TermOccurrence(1,1,1),\n",
    "                            TermOccurrence(3,1,1)],\n",
    "                     \"plutao\":[TermOccurrence(2,5,1),\n",
    "                               TermOccurrence(4,5,1)],\n",
    "                        \"terra\":[TermOccurrence(1,2,1),\n",
    "                            TermOccurrence(2,2,1),\n",
    "                            TermOccurrence(4,2,1),],\n",
    "                        \"venus\":[TermOccurrence(1,3,1),\n",
    "                                TermOccurrence(2,3,1),\n",
    "                                TermOccurrence(3,3,1),\n",
    "                                TermOccurrence(4,3,1)],\n",
    "                        \"marte\":[TermOccurrence(1,4,2),\n",
    "                            TermOccurrence(3,4,1),\n",
    "                            TermOccurrence(4,4,1),],\n",
    "\n",
    "                        \"mercurio\":[TermOccurrence(3,6,1)]          \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1,2,3}|{2,4}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A intereseção entre `saturno` e `venus` resultará nos documentos 1 e 3 e, a união, nos documentos 1, 2, 3 e 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é uma forma bem simplificada para implementarmos o modelo booleano. Para isso, você deverá implementar os métodos `union_all` e `intersection_all` presentes na classe `BooleanRankingModel` no arquivo `ranking_models.py`. Esses métodos recebem como parâmetro um mapa com a lista de correncias de cada termo (similar a exemplificada acima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_boolean_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 2 - TF-IDF:** Agora, no mesmo arquivo, iremos finalizar a implementação do modelo Vetorial utilizando a classe `VectorRankingModel`. Nesta classe, primeiramente, você deverá implementar os [métodos estáticos](https://daniel-hasan.github.io/cefet-web-grad/classes/python2/) `tf`, `idf` e `tf_idf`. Sendo que $TF = 1+log_2(f_{ij})$ e $IDF_i = log_2(\\frac{N}{n_i})$ em que $f_{ij}$ é a frequência do termo $i$ no documento $j$, $N$ é o número de documentos e $n_i$ é o número de documentos que ocorrem o termo $i$. Abaixo, faça testes destes métodos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 6.906890595608519\n",
      "idf: 3.3219280948873626\n",
      "tf_idf: 22.94419391786525\n"
     ]
    }
   ],
   "source": [
    "from query.ranking_models import VectorRankingModel\n",
    "\n",
    "doc_count = 300\n",
    "term_frequency = 60\n",
    "doc_frequency = 30\n",
    "\n",
    "tf = VectorRankingModel.tf(term_frequency)\n",
    "idf = VectorRankingModel.idf(doc_count, doc_frequency)\n",
    "tf_idf = VectorRankingModel.tf_idf(doc_count, term_frequency, doc_frequency)\n",
    "\n",
    "print(f\"tf: {tf}\")\n",
    "print(f\"idf: {idf}\")\n",
    "print(f\"tf_idf: {tf_idf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3 - PreComputedVals:** No modelo vetorial temos que calcular a norma de cada documento $d_j$. Esse cálculo pode ser feito durante o preprocessamento da consulta. Assim, a classe `IndexPreComputedVals` possui o atributo `document_norm` que é um dicionário que mapeia cada documento $j$ à sua norma. Esse calculo é feito apenas uma vez ao iniciar o programa. \n",
    "\n",
    "Desta forma, você deverá terminar de implementar o método `precompute_vals` que percorre todo o índice e armazena a norma de cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.115s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_precomputed_vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 4 - Método `get_ordered_docs` da classe `VectorRankingModel`:** Usando os métodos implementados anteriormente você deverá ordenar os documentos contidos no mapa de ocorrencias `docs_occur_per_term` de acordo com a consulta `query` utilizando o modelo vetorial. O parametro `query` mapeia um termo presente na consulta, para a sua ocorrencia (objeto da classe `TermOcurrence`) na propria consulta. \n",
    "\n",
    "Para cada termo $t$ que ocorre na consulta, `docs_occur_per_term` mapeia cada termo com a lista de ocorrencias dele no índice. Veja abaixo um exemplo destes parametros usando a consulta `to be or not to be`.  Veja que, na consulta, `doc_id = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.index.structure import TermOccurrence\n",
    "query = {\n",
    "    \"to\":TermOccurrence(None, 1, 2),\n",
    "    \"be\":TermOccurrence(None, 2, 2),\n",
    "    \"or\":TermOccurrence(None, 3, 1),\n",
    "    \"not\":TermOccurrence(None, 4, 1),\n",
    "}\n",
    "\n",
    "docs_occur_per_term = {\n",
    "    \"to\":[TermOccurrence(1, 1, 4), TermOccurrence(2, 1, 1),],\n",
    "    \"be\":[TermOccurrence(1, 2, 1),TermOccurrence(2, 2, 1)],\n",
    "    \"or\":[TermOccurrence(2, 3, 1)],\n",
    "    \"not\":[TermOccurrence(3, 4, 1)],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, temos a consulta (representado pela variavel `query`) 'to to be be or not', ou seja, o `to` e o `be` ocorrendo duas vezes na consulta e, os demais termos, uma vez - a ordem não é definida no parametro. Em `docs_occcur_per_term` temos a ocorrencia desses termos nos documentos da coleção. \n",
    "\n",
    "Você deve executar o modelo vetorial para obter o resultado `documents_weight` que mapeia, para cada documento a similaridade entre ele e a consulta utilizando o modelo vetorial e a distancia do cosseno. Note que neste método você **não** pode navegar por todos os documentos da coleção pois, caso seja feito isso, o código de vocês iriam demorar muito caso sua coleção tiver milhões ou bilhões de documentos. Uma dica é usar o `documents_weight` para armazenar os valores intermediarios do somatorio de $w_{ij} \\times  w_{iq}$, tais variáveis são definidas nos [slides de modelagem vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing). \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse método retorna dois valores: (a) uma lista de ids de documentos ordenada de acordo com o modelo vetorial - use o método e um dicionário que mapeia, para cada documento, o seu peso. O método `rank_document_ids` será útil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_vector_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento da Consulta e Avaliação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora você irá fazer o processamento da consulta, informada pelo usuário, além de sua avaliação. A implementação do processamento de consultas será feito na classe `QueryRunner` do arquivo `processing.py`.\n",
    "\n",
    "**Requisito antes de começar:** o código que foi feito da indexação deve estar funcionando. Será utilizado a base de dados da Wikipédia. Você não deverá fazer a indexação toda quando iniciar o programa, ao invés disso, você deve persistir o indice todo em arquivo após a indexação. Usando FileIndex, como as ocorrencias já estão armazenadas em arquivo, você precisa armazenar apenas o conteúdo do `dic_index`. A [biblioteca json](https://docs.python.org/3/library/json.html) pode ajudar. Este índice será lido do arquivo apenas uma vez no início da execução do programa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criação da coleção de referência:** Para o projeto realizaremos uma avaliação bem simples, com o único intuito de simularmos um processo real de avaliação. Para tanto, consideraremos como conjunto de consultas de teste apenas três consultas:\n",
    "'Irlanda'\n",
    "'Belo Horizonte' e \n",
    "'São Paulo'\n",
    "\n",
    "O conjunto de documentos de teste compreenderá todas as páginas da base de dados da Wikipédia PT-BR utilizadas no projeto.  Para cada consulta, disponibilizamos um arquivo (na pasta `relevant_docs`) com o id de documentos relevantes (separados por vírgula) para as consultas teste.\n",
    "\n",
    "Por exemplo, um documento $D$ será considerado relevante para a consulta 'Belo Horizonte' somente \n",
    "se o id de $D$ estiver no arquivo `belo_horizonte.dat`. Você irá armazenar o conteúdo desses arquivos em memória para diminuir o tempo de busca. Feito isso, a coleção de referência para as três consultas estará montada e pode-se realizar os cálculos de avaliação corretamente.\n",
    "\n",
    "**Como um artigo foi considerado relevante para uma determinada consulta?** A Wikipedia organiza seus artigos em diversas categorias. Assim, para considerarmos se um artigo da Wikipédia é relevante, utilizamos essas categorias. Assim, para os documentos relevantes para a consulta 'Irlanda' (Arquivo `irlanda.dat`), foram considerados relevantes artigos da seguintes categorias: \n",
    " \n",
    "- Irlanda\n",
    "- Economia da Irlanda\n",
    "- História da Irlanda\n",
    "- Cultura da Irlanda\n",
    "- Romancistas da Irlanda\n",
    "- Físicos da Irlanda\n",
    "- Reis da Irlanda\n",
    "- Lordes da Irlanda\n",
    "\n",
    "Categorias relevantes para a consulta 'Belo Horizonte' (Arquivo `belo_horizonte.dat`): \n",
    "\n",
    "- Bairros de Belo Horizonte\n",
    "- Bandas de Belo Horizonte\n",
    "- Belo Horizonte\n",
    "- Edifícios de Belo Horizonte\n",
    "- Metrô de Belo Horizonte\n",
    "- Naturais de Belo Horizonte\n",
    "- Prefeitos de Belo Horizonte\n",
    "- Vereadores de Belo Horizonte\n",
    "\n",
    "Categorias relevantes para a consulta 'São Paulo' (arquivo `sao_paulo.dat`):\n",
    "\n",
    "- Atrações turísticas da cidade de São Paulo\n",
    "- Áreas protegidas de São Paulo\n",
    "- Prefeitos de São Paulo\n",
    "- São Paulo\n",
    "- Turismo em São Paulo\n",
    "- Universidades de São Paulo\n",
    "- Rodovias de São Paulo\n",
    "- Museus da cidade de São Paulo\n",
    "- Governadores de São Paulo\n",
    "- Municípios de São Paulo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 5 - Leitura dos arquivos de relevâncias:** Você deverá implementar o método `get_relevance_per_query` que irá ler todos os arquivo da pasta `relevant_docs` e, com isso, retornar um mapeamento em que a chave é a string de consulta e o valor é o **conjunto** de ids de documentos. Veja um exemplo de retorno com as consultas `Bolívia`, `Brasil` e `Porto Seguro`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retorno = {\"Bolívia\":{1,3,5,6,233},\n",
    "            \"Brasil\":{2,4,5,3},\n",
    "           \"Porto Seguro\":{3,43,21,3,12,233}\n",
    "          }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça um teste de execução abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'belo_horizonte': {'18111', '110030', '125549', '35985', '47967', '97000', '80198', '49186', '38636', '91593', '106575', '101043', '136473\\n', '107302', '136473', '108604', '43658', '484', '49772', '130173', '104137', '1083', '69168', '40226', '29241', '91853', '19588'}, 'irlanda': {'15393', '95773', '43872', '37632', '44259', '111966', '93223', '33833', '37935', '124818\\n', '54836', '3765', '105348', '52998', '46441', '83228', '47185', '52995', '51779', '51714', '26276', '105145', '7765', '1393', '13256', '102888', '1196', '45577', '58189', '51786', '53004', '39049', '51778', '1034', '11953', '51716', '39300', '9918', '9955'}, 'sao_paulo': {'35241', '127303', '34894', '34965', '34934', '17768', '35218', '63123', '35161', '41967', '34950', '35240', '10756', '34813', '7847', '34963', '34871', '34971', '37240', '77762', '35052', '29476', '31879', '35023', '37054', '34893', '96945', '57810', '34945', '33643', '70457', '18515', '34847', '34955', '35193', '35063', '120839', '40127', '34815', '62759', '18489', '25107', '30016', '47240', '35194', '35875', '30658', '3546', '34952', '95286', '52391', '34914', '37244', '38535', '37600', '35077', '34812', '34981', '34923', '63775', '37256', '35034', '35165', '128145', '30119', '35058', '35007', '23439', '34858', '34970', '35026', '113999', '34844', '105368', '23505', '34831', '35011', '29459', '35114', '35198', '35225', '34806', '35132', '34943', '34794', '35028', '34896', '107604', '35214', '35093', '117951', '34791', '35029', '58490', '35177', '41906', '33739', '35145', '35126', '17703', '34931', '35224', '37249', '37087', '35032', '35201', '34953', '34918', '34895', '120284', '34787', '35039', '27897', '34932', '130359', '18411', '18143', '35031', '60431', '35059', '35098', '37241', '34978', '35183', '70209', '32353', '35021', '34798', '37053', '72332', '55965', '35166', '35212', '94770', '35115', '34832', '33267', '103495', '34902', '34933', '35076', '132004', '60377', '64679', '35148', '34939', '35157', '34886', '35043', '35189', '44596', '124032', '37252', '125876', '34840', '118365', '35221', '15814', '106867', '121580', '34778', '34808', '34868', '35124', '37274', '35055', '34880', '45081', '96952', '24089', '17422', '59093', '64326', '34987', '34849', '34837', '110131', '34890', '35151', '105372', '35123', '35186', '108256', '50674', '45239', '37243', '26173', '35112', '30654', '60430', '35000', '35174', '9277', '35140', '34855', '35164', '37282', '127538', '30641', '58426', '112599', '35125', '35229', '34901', '1084', '34882', '35069', '131865', '114888', '100337', '31889', '35197', '104490', '34820', '18307', '37056', '23412', '34869', '35038', '71322', '34912', '120283', '9258', '727', '31886', '34892', '35035', '121946', '53833', '34786', '34776', '34969', '96931', '31880', '130272', '29477', '34785', '35204', '35073', '35134', '35158', '23441', '35102', '123161', '24546', '41964', '107278', '34627', '72497', '34982', '104847', '41955', '34959', '34825', '35004', '34897', '35233', '110916', '34862', '35182', '35066', '35092', '33530', '67685', '35067', '32573', '9928', '35181', '34999', '53155', '35156', '8170', '41971', '35117', '34906', '34935', '135137\\n', '35171', '34919', '110315', '35235', '62764', '35213', '129465', '34879', '34984', '34885', '96944', '35155', '34876', '47510', '21467', '35054', '35083', '35130', '35168', '117875', '35227', '58105', '35101', '44001', '34915', '34990', '44043', '44027', '130537', '34807', '34985', '34979', '123768', '37255', '30653', '35175', '35070', '23402', '34800', '34861', '35099', '35109', '35153', '120719', '1719', '34606', '91915', '35139', '1291', '12383', '11478', '37085', '63584', '114625', '34850', '34851', '31202', '52388', '78432', '101163', '64908', '35167', '35163', '83535', '61190', '114091', '35149', '35135', '34779', '34941', '42255', '35216', '34962', '34975', '67301', '44033', '7687', '30640', '35231', '34940', '36238', '35202', '35210', '35222', '34995', '37258', '35108', '35049', '29427', '34699', '66592', '18482', '35173', '68791', '41942', '17661', '46533', '44836', '49745', '12218', '34819', '111222', '35030', '34836', '34907', '34845', '42765', '35188', '13726', '34958', '67061', '34891', '35036', '34983', '37265', '120924', '98274', '132679', '16865', '103736', '99800', '23413', '1324', '62828', '35012', '63827', '115341', '35122', '34936', '105369', '123706', '34888', '35230', '34972', '63776', '29460', '35100', '19963', '37283', '61403', '30402', '63702', '34903', '116539', '35002', '34992', '35150', '23988', '31890', '124692', '34968', '41945', '35046', '35239', '35064', '15837', '115646', '67967', '21504', '41948', '111495', '103003', '18305', '35079', '35162', '35022', '54087', '18364', '65568', '52221', '103262', '23990', '35206', '10558', '132760', '35020', '33850', '34822', '35170', '124892', '9744', '35143', '34908', '34777', '35238', '54428', '34874', '34852', '35087', '35110', '34974', '34841', '63715', '34878', '116543', '107841', '53269', '22159', '128906', '23983', '26805', '37242', '35027', '35041', '64678', '34803', '63617', '41958', '27860', '41961', '30669', '34653', '34872', '35006', '37297', '1752', '34967', '54205', '42582', '41944', '24007', '124267', '34986', '18312', '63586', '34784', '35119', '43939', '47221', '34911', '34926', '34991', '67965', '63613', '24088', '12381', '34863', '34930', '35086', '35089', '35111', '76506', '117843', '34921', '35048', '34900', '35226', '35144', '78269', '35095', '34613', '10792', '30667', '41761', '35074', '35217', '35196', '359', '34873', '34937', '35160', '35207', '34998', '34821', '34830', '18769', '35131', '37261', '34857', '35205', '37247', '74190', '128635', '30649', '22647', '49752', '34814', '11664', '35195', '84257', '35040', '34843', '820', '121025', '34898', '34824', '34928', '56690', '35001', '113733', '34809', '110028', '32738', '16722', '34773', '18285', '125623', '35215', '63593', '18299', '108677', '34865', '63637', '34829', '71920', '30652', '34770', '35141', '35056', '35113', '36655', '35061', '31888', '34884', '35047', '125486', '36511', '35024', '35138', '71254', '35223', '126579', '50702', '71562', '23420', '56310', '31882', '35184'}}\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.102s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_get_relevance_per_query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 6 - count_top_n_relevant:** Um método que auxilirará vocês na avaliação é o método count_top_n_relevant da classe Query Runner.  Esse método calcula a quantidade de documentos relevantes nas top `n` posições da lista `lstResposta` que é a resposta a uma consulta - lista de ids de documentos. `lstResposta` será a lista de respostas ordenadas por um método de processamento de consulta (BM25, Modelo vetorial). Os ids de documentos relevantes estão no parametro `docRelevantes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.104s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_count_top_n_relevant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 7 - processamento da consulta**: O método `get_query_term_occurence` a consulta da mesma forma que foi preprocessado o texto do documento (use a classe `Cleaner` para isso). Este método irá retonar a consulta em um dicionario em que chave é o termo que ocorreu e o valor é uma instancia da classe TermOccurrence (ver Atividade 4). O doc_id deverá ser sempre None. Caso o termo nao exista no indice, ele será desconsiderado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta: crocodilo\n",
      "Resposta do método: {}\n",
      "\n",
      "Consulta: vocês\n",
      "Resposta do método: {'vocês': ( doc: None term_id:1 freq: 1)}\n",
      "\n",
      "Consulta: Vocês estejam\n",
      "Resposta do método: {'vocês': ( doc: None term_id:1 freq: 1), 'estejam': ( doc: None term_id:4 freq: 1)}\n",
      "\n",
      "Consulta: vocês vocês crocodilo\n",
      "Resposta do método: {'vocês': ( doc: None term_id:1 freq: 2)}\n",
      "\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.114s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_get_query_term_occurence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 8 - Recuperação dos termos da consulta no índice:** O método `get_occurrence_list_per_term` possui com parametro a lista de termos da consulta. Este método retorna um dicionario com a lista de ocorrencia no indice de cada termo passado como parametro. Caso o termo não exista, este termo possuirá uma lista vazia. Veja o exemplo na atividade 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termos: ['crocodilo']\n",
      "Resposta do método: {'crocodilo': []}\n",
      "\n",
      "Termos: ['vocês', 'estejam', 'crocodilo']\n",
      "Resposta do método: {'vocês': [( doc: 2 term_id:1 freq: 3), ( doc: 3 term_id:1 freq: 1)], 'estejam': [( doc: 3 term_id:4 freq: 1)], 'crocodilo': []}\n",
      "\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.105s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_get_occurence_list_per_term"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 9 - processamento da consulta:** Este método recebe como parametro a consulta, os valores precomputado do índice e o dicionário de documentos relevantes (extraídos do método `get_relevance_per_query`) para retornar uma lista de IDs ordenados de acordo com a consulta utilizando o modelo de ranking e indice que são os atributos `index` e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos dos documento da consulta 'crocodilo': {}\n",
      "\n",
      "Pesos dos documento da consulta 'vocês': {2: 0.40378886090583005, 3: 0.12190858668225728}\n",
      "\n",
      "Pesos dos documento da consulta 'Vocês estejam': {2: 0.40378886090583005, 3: 1.0168945556805116}\n",
      "\n",
      "Pesos dos documento da consulta 'vocês vocês crocodilo': {2: 0.8075777218116601, 3: 0.24381717336451456}\n",
      "\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.198s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_get_docs_term"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 10: Método estático runQuery e criação da interface de caracteres - ou uso da interface gráfica/web:** Você deverá implementar o método `runQuery` que utilizando o indice, valores precomputados e o dicionario de indices relevantes irá fazer:\n",
    "\n",
    "- Instanciar um objeto de uma subclasse de RankingModel, de acordo com o que foi solicitado pelo usuário\n",
    "- Preprocessar os termos da consulta\n",
    "- Obter no indice as ocorrencias de cada termo do indice\n",
    "- Utilize o método get_docs_term para obter a lista de documentos que responde esta consulta\n",
    "- Caso seja uma consulta que possua documentos relevantes assinalados, fazer a avaliação da precisão e revocação dos top 10, 20 e 50\n",
    "- Imprimir as top 10 respostas. \n",
    "\n",
    "Caso  opte por fazer uma interface de web, você não precisará de fazer este método em especifico  - nem o `main`, explicado a seguir - , mas, deverá possibilitar o usuário entre com uma consulta e retorne as top 10 respostas além de imprimir a precisão e revocação dos top 10, 20 e 50 das consultas que possuem documentos relevantes assinalados. \n",
    "            \n",
    "Caso opte por implementar uma interface de carcteres você deverá terminar de implementar o método `main` para solicitar ao usuário a consulta e execute-a abaixo. Caso deseje, ao inves disso, você pode também fazer uma interface gráfica. Para testar este método, você deverá usar o indice da Wikipedia, assim, ele deve ser lido no início do programa. Você tem a liberdade de alterar este método como bem entender, mas lembre-se que os valores precomputados devem ser executado uma vez só durante a execução do programa antes da solicitação das consultas para que a consulta não fique lenta. Além disso, você deve ler o arquivo do índice também apenas uma vez (não indexe a Wikipedia novamente e sim leia o arquivo do indice gravado em memória). Caso deseje, você pode modificar o IndexPreComputedVals para armazenar mais elementos precomputados que facilitariam a consulta (ou a exibição da mesma). \n",
    "\n",
    "\n",
    "Para melhorar a apresentação, o arquivo `titlePerDoc.dat` apresenta o título do artigo por id do mesmo. Além disso, você deverá fazer uma análise e acordo com o [guia de escrita do relatório](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.bsvivts5y2ld) considerando as [tarefas do Trabalho Prático 3](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.fh1qug6oeoe7).\n",
    "\n",
    "\n",
    "Caso opte por fazer uma interface web, deve estar claro, neste Jupyter, as instruções para que seja possível executa-la, inclusive, as suas dependencias. Para melhoria de organização, a parte de interface grafica ou web deve ser feita em outros arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice lido com sucesso\n",
      "Precomputando valores atraves do indice...\n",
      "Precomputou valores done in 19.514244\n",
      "Cleaner instanciado com sucesso\n",
      "\n",
      "===========================================\n",
      "Fazendo query de 'belo horizonte'...\n",
      "Modelo Booleano AND escolhido\n",
      "\n",
      "Query Creation done in 3.313389\n",
      "anwered with 877 docs\n",
      " done in 0.006513\n",
      "Precisao @5: 0.0\n",
      "Recall @5: 0.0\n",
      "Precisao @10: 0.0\n",
      "Recall @10: 0.0\n",
      "Precisao @20: 0.05\n",
      "Recall @20: 0.030303030303030304\n",
      "Precisao @50: 0.04\n",
      "Recall @50: 0.06060606060606061\n",
      "\n",
      "Top 10:\n",
      "22528: Partido Democrático Trabalhista\n",
      "32768: Varzelândia\n",
      "32769: Vazante\n",
      "32771: Veredinha\n",
      "75777: Sociedade Esportiva Palestra Itália\n",
      "34826: Campos do Jordão\n",
      "57355: Deslizamento de terra\n",
      "32780: Volta Grande\n",
      "118801: Paul Singer\n",
      "26642: São José do Goiabal\n",
      "\n",
      "Bottom 10:\n",
      "32767: Várzea da Palma\n",
      "22525: Partido da Social Democracia Brasileira\n",
      "34811: Bragança Paulista\n",
      "49141: Megalópole\n",
      "32757: Unaí\n",
      "32756: Umburatiba\n",
      "30708: Assaré\n",
      "14324: Gol Linhas Aéreas Inteligentes\n",
      "32755: Uberaba\n",
      "83954: Baía de Sepetiba\n",
      "\n",
      "===========================================\n",
      "Fazendo query de 'irlanda'...\n",
      "Modelo Booleano OR escolhido\n",
      "\n",
      "Query Creation done in 1.592032\n",
      "anwered with 766 docs\n",
      " done in 0.0\n",
      "Precisao @5: 1.0\n",
      "Recall @5: 0.10204081632653061\n",
      "Precisao @10: 0.7\n",
      "Recall @10: 0.14285714285714285\n",
      "Precisao @20: 0.35\n",
      "Recall @20: 0.14285714285714285\n",
      "Precisao @50: 0.2\n",
      "Recall @50: 0.20408163265306123\n",
      "\n",
      "Top 10:\n",
      "122881: Enya\n",
      "12295: Organização das Nações Unidas para Alimentação e Agricultura\n",
      "106517: Samuel Ferguson\n",
      "43033: Subdivisões do Reino Unido\n",
      "83994: Papa Agatão\n",
      "51227: Geografia de Papua-Nova Guiné\n",
      "43039: EBay\n",
      "53282: Casa de Hanôver\n",
      "18470: Barcelona\n",
      "114728: Sinéad O'Connor\n",
      "\n",
      "Bottom 10:\n",
      "92159: Eddie the Head\n",
      "61435: Americanismo\n",
      "22520: Jogos Olímpicos de Verão de 1896\n",
      "12265: Energia eólica\n",
      "26600: Guerra Civil Espanhola\n",
      "67556: William Butler Yeats\n",
      "10212: Comunidade Económica Europeia\n",
      "38878: Batalha de Alcácer-Quibir\n",
      "94173: Terra do Fogo\n",
      "63447: Exército Republicano Irlandês\n",
      "\n",
      "===========================================\n",
      "Fazendo query de 'sao paulo'...\n",
      "Modelo Vetorial escolhido\n",
      "\n",
      "Query Creation done in 1.09097\n",
      "anwered with 26519 docs\n",
      " done in 0.0421\n",
      "Precisao @5: 0.4\n",
      "Recall @5: 0.0032733224222585926\n",
      "Precisao @10: 0.7\n",
      "Recall @10: 0.011456628477905073\n",
      "Precisao @20: 0.35\n",
      "Recall @20: 0.011456628477905073\n",
      "Precisao @50: 0.34\n",
      "Recall @50: 0.027823240589198037\n",
      "\n",
      "Top 10:\n",
      "73731: Rio Vermelho (rio de São Paulo)\n",
      "63160: Mosteiro de São Bento de São Paulo\n",
      "73702: Rio Paulo Diniz\n",
      "73605: Rio Doce (São Paulo)\n",
      "24070: Claro (desambiguação)\n",
      "55480: São Mateus (distrito de São Paulo)\n",
      "61441: Pedreira (distrito de São Paulo)\n",
      "24734: Paulo Bento\n",
      "18489: Luís Inácio de Anhaia Melo\n",
      "45081: Mercado Municipal de São Paulo\n",
      "\n",
      "Bottom 10:\n",
      "18588: Mary Shelley\n",
      "59158: Georges Méliès\n",
      "119216: Eliminatórias da Copa do Mundo FIFA de 2006 - Europa\n",
      "133178: Óscar de melhor ator secundário\n",
      "43735: Guns N' Roses\n",
      "65517: Yoda\n",
      "58210: Weezer\n",
      "682: Tiësto\n",
      "107230: Robin Williams\n",
      "124266: Toronto Maple Leafs\n",
      "\n",
      "===========================================\n",
      "  Saindo...\n"
     ]
    }
   ],
   "source": [
    "from query.processing import QueryRunner\n",
    "\n",
    "QueryRunner.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando interface...\n",
      "Preprocessando dados...\n",
      "\n",
      "Indice lido com sucesso\n",
      "Precomputando valores atraves do indice...\n",
      "Precomputou valores done in 13.244147\n",
      "Cleaner instanciado com sucesso\n",
      "Belo Horizonte\n",
      "Belo Horizonte\n",
      "Modelo Booleano AND escolhido\n",
      "\n",
      "Query Creation done in 0.0\n",
      "anwered with 877 docs\n",
      " done in 0.006021\n",
      "Precisao @5: 0.0\n",
      "Recall @5: 0.0\n",
      "Precisao @10: 0.0\n",
      "Recall @10: 0.0\n",
      "Precisao @20: 0.05\n",
      "Recall @20: 0.030303030303030304\n",
      "Precisao @50: 0.04\n",
      "Recall @50: 0.06060606060606061\n"
     ]
    }
   ],
   "source": [
    "from query.interface import Interface\n",
    "\n",
    "Interface.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
