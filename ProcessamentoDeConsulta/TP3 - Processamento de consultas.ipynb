{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto você irá implementar o processamento de consultas. Nela, você utilizará o índice para retornar uma coleção ordenada e avaliação de algumas consultas selecionadas. Para isso, vocês deverão implementar alguns métodos das seguintes classes.\n",
    "\n",
    "- `IndexPreComputedVals`: Em alguns modelos, há a necessidade de processar alguns valores para que, no momento da execução da consulta, seja retornado de forma mais rápida. Esta classe analisa o índice e armazena informações necessárias para o calculo de cada tipo de modelagem;\n",
    "- `RankingModel`: Classe abstrata para a criação dos modelos. Ele possui o método `get_ordered_docs` a ser implementado por suas subclasses;\n",
    "- `BooleanRankingModel` Classe que retorna um resultado de consulta por meio do [modelo booleano](https://docs.google.com/presentation/d/1V62ll_IXRrsp6TYUHjx_T4jIyIc1ZVJYoOSwsxObybE/edit?usp=sharing)\n",
    "- `VectorRankingModel`: Classe que retorna um resultado de consulta por meio do [modelo vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing)\n",
    "- `QueryRunner`: Classe principal encarregada de obter a consulta e retornar os resultados;\n",
    "\n",
    "\n",
    "Este trabalho depende do código do indice (pacote `index`). Assim, você deve adicioná-o apropriadamente para dar continuidade ao projeto. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem Booleana e Vetorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 1 - Modelagem Booleana**: A abordagem booleana neste trabalho é simplificada. O modelo recebe o atributo `operator` que é uma instancia do [Enum](https://docs.python.org/3.4/library/enum.html) Operator. Caso o operador seja AND, será feito a operacao de interseção entre todos os documentos contidos ocorrencias de palavras, caso contrario, sendo OR, será feito a união. Exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.index.structure import TermOccurrence\n",
    "map_ocorrencias = {\"saturno\":[TermOccurrence(1,1,1),\n",
    "                            TermOccurrence(3,1,1)],\n",
    "                     \"plutao\":[TermOccurrence(2,5,1),\n",
    "                               TermOccurrence(4,5,1)],\n",
    "                        \"terra\":[TermOccurrence(1,2,1),\n",
    "                            TermOccurrence(2,2,1),\n",
    "                            TermOccurrence(4,2,1),],\n",
    "                        \"venus\":[TermOccurrence(1,3,1),\n",
    "                                TermOccurrence(2,3,1),\n",
    "                                TermOccurrence(3,3,1),\n",
    "                                TermOccurrence(4,3,1)],\n",
    "                        \"marte\":[TermOccurrence(1,4,2),\n",
    "                            TermOccurrence(3,4,1),\n",
    "                            TermOccurrence(4,4,1),],\n",
    "\n",
    "                        \"mercurio\":[TermOccurrence(3,6,1)]          \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1,2,3}|{2,4}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A intereseção entre `saturno` e `venus` resultará nos documentos 1 e 3 e, a união, nos documentos 1, 2, 3 e 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é uma forma bem simplificada para implementarmos o modelo booleano. Para isso, você deverá implementar os métodos `union_all` e `intersection_all` presentes na classe `BooleanRankingModel` no arquivo `ranking_models.py`. Esses métodos recebem como parâmetro um mapa com a lista de correncias de cada termo (similar a exemplificada acima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_boolean_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 2 - TF-IDF:** Agora, no mesmo arquivo, iremos finalizar a implementação do modelo Vetorial utilizando a classe `VectorRankingModel`. Nesta classe, primeiramente, você deverá implementar os [métodos estáticos](https://daniel-hasan.github.io/cefet-web-grad/classes/python2/) `tf`, `idf` e `tf_idf`. Sendo que $TF = 1+log_2(f_{ij})$ e $IDF_i = log_2(\\frac{N}{n_i})$ em que $f_{ij}$ é a frequência do termo $i$ no documento $j$, $N$ é o número de documentos e $n_i$ é o número de documentos que ocorrem o termo $i$. Abaixo, faça testes destes métodos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 6.906890595608519\n",
      "idf: 3.3219280948873626\n",
      "tf_idf: 22.94419391786525\n"
     ]
    }
   ],
   "source": [
    "from query.ranking_models import VectorRankingModel\n",
    "\n",
    "doc_count = 300\n",
    "term_frequency = 60\n",
    "doc_frequency = 30\n",
    "\n",
    "tf = VectorRankingModel.tf(term_frequency)\n",
    "idf = VectorRankingModel.idf(doc_count, doc_frequency)\n",
    "tf_idf = VectorRankingModel.tf_idf(doc_count, term_frequency, doc_frequency)\n",
    "\n",
    "print(f\"tf: {tf}\")\n",
    "print(f\"idf: {idf}\")\n",
    "print(f\"tf_idf: {tf_idf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3 - PreComputedVals:** No modelo vetorial temos que calcular a norma de cada documento $d_j$. Esse cálculo pode ser feito durante o preprocessamento da consulta. Assim, a classe `IndexPreComputedVals` possui o atributo `document_norm` que é um dicionário que mapeia cada documento $j$ à sua norma. Esse calculo é feito apenas uma vez ao iniciar o programa. \n",
    "\n",
    "Desta forma, você deverá terminar de implementar o método `precompute_vals` que percorre todo o índice e armazena a norma de cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.095s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_precomputed_vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 4 - Método `get_ordered_docs` da classe `VectorRankingModel`:** Usando os métodos implementados anteriormente você deverá ordenar os documentos contidos no mapa de ocorrencias `docs_occur_per_term` de acordo com a consulta `query` utilizando o modelo vetorial. O parametro `query` mapeia um termo presente na consulta, para a sua ocorrencia (objeto da classe `TermOcurrence`) na propria consulta. \n",
    "\n",
    "Para cada termo $t$ que ocorre na consulta, `docs_occur_per_term` mapeia cada termo com a lista de ocorrencias dele no índice. Veja abaixo um exemplo destes parametros usando a consulta `to be or not to be`.  Veja que, na consulta, `doc_id = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.index.structure import TermOccurrence\n",
    "query = {\n",
    "    \"to\":TermOccurrence(None, 1, 2),\n",
    "    \"be\":TermOccurrence(None, 2, 2),\n",
    "    \"or\":TermOccurrence(None, 3, 1),\n",
    "    \"not\":TermOccurrence(None, 4, 1),\n",
    "}\n",
    "\n",
    "docs_occur_per_term = {\n",
    "    \"to\":[TermOccurrence(1, 1, 4), TermOccurrence(2, 1, 1),],\n",
    "    \"be\":[TermOccurrence(1, 2, 1),TermOccurrence(2, 2, 1)],\n",
    "    \"or\":[TermOccurrence(2, 3, 1)],\n",
    "    \"not\":[TermOccurrence(3, 4, 1)],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, temos a consulta (representado pela variavel `query`) 'to to be be or not', ou seja, o `to` e o `be` ocorrendo duas vezes na consulta e, os demais termos, uma vez - a ordem não é definida no parametro. Em `docs_occcur_per_term` temos a ocorrencia desses termos nos documentos da coleção. \n",
    "\n",
    "Você deve executar o modelo vetorial para obter o resultado `documents_weight` que mapeia, para cada documento a similaridade entre ele e a consulta utilizando o modelo vetorial e a distancia do cosseno. Note que neste método você **não** pode navegar por todos os documentos da coleção pois, caso seja feito isso, o código de vocês iriam demorar muito caso sua coleção tiver milhões ou bilhões de documentos. Uma dica é usar o `documents_weight` para armazenar os valores intermediarios do somatorio de $w_{ij} \\times  w_{iq}$, tais variáveis são definidas nos [slides de modelagem vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing). \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse método retorna dois valores: (a) uma lista de ids de documentos ordenada de acordo com o modelo vetorial - use o método e um dicionário que mapeia, para cada documento, o seu peso. O método `rank_document_ids` será útil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_vector_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento da Consulta e Avaliação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora você irá fazer o processamento da consulta, informada pelo usuário, além de sua avaliação. A implementação do processamento de consultas será feito na classe `QueryRunner` do arquivo `processing.py`.\n",
    "\n",
    "**Requisito antes de começar:** o código que foi feito da indexação deve estar funcionando. Será utilizado a base de dados da Wikipédia. Você não deverá fazer a indexação toda quando iniciar o programa, ao invés disso, você deve persistir o indice todo em arquivo após a indexação. Usando FileIndex, como as ocorrencias já estão armazenadas em arquivo, você precisa armazenar apenas o conteúdo do `dic_index`. A [biblioteca json](https://docs.python.org/3/library/json.html) pode ajudar. Este índice será lido do arquivo apenas uma vez no início da execução do programa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criação da coleção de referência:** Para o projeto realizaremos uma avaliação bem simples, com o único intuito de simularmos um processo real de avaliação. Para tanto, consideraremos como conjunto de consultas de teste apenas três consultas:\n",
    "'Irlanda'\n",
    "'Belo Horizonte' e \n",
    "'São Paulo'\n",
    "\n",
    "O conjunto de documentos de teste compreenderá todas as páginas da base de dados da Wikipédia PT-BR utilizadas no projeto.  Para cada consulta, disponibilizamos um arquivo (na pasta `relevant_docs`) com o id de documentos relevantes (separados por vírgula) para as consultas teste.\n",
    "\n",
    "Por exemplo, um documento $D$ será considerado relevante para a consulta 'Belo Horizonte' somente \n",
    "se o id de $D$ estiver no arquivo `belo_horizonte.dat`. Você irá armazenar o conteúdo desses arquivos em memória para diminuir o tempo de busca. Feito isso, a coleção de referência para as três consultas estará montada e pode-se realizar os cálculos de avaliação corretamente.\n",
    "\n",
    "**Como um artigo foi considerado relevante para uma determinada consulta?** A Wikipedia organiza seus artigos em diversas categorias. Assim, para considerarmos se um artigo da Wikipédia é relevante, utilizamos essas categorias. Assim, para os documentos relevantes para a consulta 'Irlanda' (Arquivo `irlanda.dat`), foram considerados relevantes artigos da seguintes categorias: \n",
    " \n",
    "- Irlanda\n",
    "- Economia da Irlanda\n",
    "- História da Irlanda\n",
    "- Cultura da Irlanda\n",
    "- Romancistas da Irlanda\n",
    "- Físicos da Irlanda\n",
    "- Reis da Irlanda\n",
    "- Lordes da Irlanda\n",
    "\n",
    "Categorias relevantes para a consulta 'Belo Horizonte' (Arquivo `belo_horizonte.dat`): \n",
    "\n",
    "- Bairros de Belo Horizonte\n",
    "- Bandas de Belo Horizonte\n",
    "- Belo Horizonte\n",
    "- Edifícios de Belo Horizonte\n",
    "- Metrô de Belo Horizonte\n",
    "- Naturais de Belo Horizonte\n",
    "- Prefeitos de Belo Horizonte\n",
    "- Vereadores de Belo Horizonte\n",
    "\n",
    "Categorias relevantes para a consulta 'São Paulo' (arquivo `sao_paulo.dat`):\n",
    "\n",
    "- Atrações turísticas da cidade de São Paulo\n",
    "- Áreas protegidas de São Paulo\n",
    "- Prefeitos de São Paulo\n",
    "- São Paulo\n",
    "- Turismo em São Paulo\n",
    "- Universidades de São Paulo\n",
    "- Rodovias de São Paulo\n",
    "- Museus da cidade de São Paulo\n",
    "- Governadores de São Paulo\n",
    "- Municípios de São Paulo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 5 - Leitura dos arquivos de relevâncias:** Você deverá implementar o método `get_relevance_per_query` que irá ler todos os arquivo da pasta `relevant_docs` e, com isso, retornar um mapeamento em que a chave é a string de consulta e o valor é o **conjunto** de ids de documentos. Veja um exemplo de retorno com as consultas `Bolívia`, `Brasil` e `Porto Seguro`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retorno = {\"Bolívia\":{1,3,5,6,233},\n",
    "            \"Brasil\":{2,4,5,3},\n",
    "           \"Porto Seguro\":{3,43,21,3,12,233}\n",
    "          }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça um teste de execução abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'belo_horizonte': {'107302', '69168', '101043', '29241', '19588', '97000', '47967', '125549', '108604', '43658', '80198', '91853', '484', '110030', '104137', '136473\\n', '18111', '35985', '136473', '130173', '1083', '40226', '49186', '91593', '38636', '106575', '49772'}, 'irlanda': {'46441', '52998', '102888', '1393', '83228', '33833', '58189', '51778', '3765', '51779', '52995', '15393', '105145', '51714', '1034', '53004', '95773', '111966', '39300', '37935', '1196', '37632', '11953', '93223', '44259', '13256', '51786', '51716', '105348', '7765', '26276', '39049', '47185', '124818\\n', '9955', '43872', '9918', '54836', '45577'}, 'sao_paulo': {'37242', '64679', '34812', '34932', '41967', '34786', '34800', '35058', '120719', '35183', '18305', '35074', '35177', '34832', '59093', '64678', '16722', '35076', '61190', '63827', '113733', '34808', '34936', '37249', '34898', '50674', '64326', '54087', '57810', '63584', '110315', '72497', '125623', '32353', '35066', '23988', '35093', '35155', '40127', '43939', '18312', '128906', '35077', '103495', '34787', '35117', '24546', '24007', '34895', '34978', '22647', '35020', '30667', '35043', '34874', '34931', '34819', '24089', '35011', '62828', '34653', '35173', '34979', '35049', '108677', '35047', '130359', '34963', '34851', '10756', '35135', '35143', '71254', '56310', '107841', '34990', '101163', '132760', '12218', '33643', '66592', '110131', '35201', '35012', '34862', '34959', '31888', '35098', '35170', '35079', '35875', '35000', '34855', '34919', '34844', '35156', '104847', '35141', '35021', '23983', '35112', '35164', '34955', '35023', '34807', '17768', '34914', '34892', '36238', '33530', '23439', '105368', '30658', '34952', '71322', '124032', '34915', '11478', '42765', '95286', '12381', '35240', '727', '35061', '35067', '35069', '9744', '37053', '35122', '35181', '23990', '29476', '107278', '96931', '35040', '129465', '11664', '37297', '67685', '34815', '1324', '35233', '34983', '41961', '35029', '25107', '35215', '35030', '34791', '35111', '37054', '112599', '7847', '55965', '31890', '34897', '34968', '35139', '35073', '16865', '37265', '127538', '9258', '29459', '35087', '123706', '34986', '21467', '34982', '35032', '53155', '34814', '63637', '130272', '34822', '35026', '34820', '37243', '29427', '37256', '35189', '41955', '34891', '67061', '63586', '34824', '114625', '30640', '52391', '35160', '76506', '17661', '31879', '78269', '70209', '42582', '34896', '27897', '23412', '35165', '104490', '35134', '107604', '111222', '37255', '34890', '37258', '23441', '98274', '35046', '35132', '124692', '37261', '34912', '34901', '61403', '34831', '30119', '35207', '117951', '36511', '124267', '35167', '23402', '31889', '110916', '114091', '116539', '71562', '34699', '34934', '123161', '96944', '114888', '35151', '35108', '31886', '18489', '15837', '110028', '34902', '18411', '23505', '30669', '18482', '35031', '30649', '37247', '13726', '34969', '21504', '50702', '103736', '60377', '34950', '35193', '35229', '63617', '94770', '10792', '35206', '24088', '128145', '41964', '35039', '34882', '35092', '34863', '35001', '111495', '30402', '35148', '58426', '35070', '34918', '35202', '29460', '37274', '1719', '35038', '118365', '34869', '37085', '70457', '35205', '53269', '45239', '37283', '34999', '34908', '35123', '18769', '30652', '52388', '34798', '37282', '35055', '9277', '34923', '35056', '17703', '34945', '34885', '15814', '56690', '34985', '35222', '35210', '130537', '35035', '34813', '123768', '34987', '33850', '35126', '35110', '34873', '41958', '41948', '34784', '34852', '54428', '100337', '35063', '35235', '35041', '127303', '54205', '125876', '35124', '49752', '31880', '47510', '67301', '117875', '120924', '35198', '34984', '34847', '35034', '34958', '34849', '74190', '35230', '34794', '47221', '35182', '35007', '22159', '27860', '35036', '64908', '34850', '35130', '34770', '35196', '35223', '53833', '96952', '35204', '41945', '8170', '1752', '35175', '116543', '34803', '34872', '35144', '23420', '34911', '35024', '37252', '34627', '34861', '37056', '34840', '63123', '41906', '34606', '34995', '35140', '45081', '18307', '34868', '35004', '108256', '34884', '35218', '34991', '35221', '44001', '34830', '106867', '35238', '62764', '77762', '113999', '78432', '63776', '37244', '3546', '35225', '49745', '47240', '41942', '9928', '52221', '63613', '34974', '35101', '35114', '35059', '34858', '17422', '35145', '35083', '35100', '34933', '103003', '63702', '37240', '30654', '34871', '65568', '35239', '34928', '35089', '35166', '63715', '35150', '34845', '121580', '34778', '34894', '35157', '62759', '44033', '34940', '34930', '34876', '121025', '34821', '71920', '46533', '35226', '35125', '34773', '34893', '35109', '34971', '35095', '34937', '131865', '41761', '34900', '34906', '35241', '34972', '34809', '35197', '35186', '26805', '34998', '33267', '35048', '38535', '128635', '34886', '34879', '35102', '35162', '120283', '35171', '34806', '26173', '42255', '23413', '67967', '31202', '35002', '34939', '34907', '34888', '67965', '34962', '44027', '35214', '34779', '35064', '35168', '12383', '34836', '35131', '34825', '35052', '7687', '34992', '125486', '121946', '44596', '105369', '34865', '34970', '35138', '105372', '120839', '60431', '35153', '35194', '35188', '35217', '35231', '37087', '34941', '120284', '30641', '35149', '83535', '44836', '34967', '18515', '34921', '68791', '34943', '99800', '115646', '34777', '33739', '31882', '103262', '820', '35028', '34953', '34843', '36655', '35119', '135137\\n', '18143', '84257', '35161', '35022', '30653', '34926', '34880', '41944', '30016', '117843', '34903', '18299', '32738', '1084', '35174', '34878', '35006', '10558', '58490', '34935', '132004', '18364', '34613', '115341', '35054', '35115', '37241', '34965', '35099', '34829', '34981', '34975', '41971', '19963', '35195', '35184', '35163', '34857', '35027', '35086', '44043', '35216', '60430', '34785', '32573', '359', '72332', '35227', '34776', '124892', '35158', '63593', '34837', '96945', '18285', '91915', '37600', '35213', '126579', '35224', '35113', '58105', '132679', '34841', '29477', '1291', '63775', '35212'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.091s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_get_relevance_per_query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 6 - count_top_n_relevant:** Um método que auxilirará vocês na avaliação é o método count_top_n_relevant da classe Query Runner.  Esse método calcula a quantidade de documentos relevantes nas top `n` posições da lista `lstResposta` que é a resposta a uma consulta - lista de ids de documentos. `lstResposta` será a lista de respostas ordenadas por um método de processamento de consulta (BM25, Modelo vetorial). Os ids de documentos relevantes estão no parametro `docRelevantes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.094s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_count_top_n_relevant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 7 - processamento da consulta**: O método `get_query_term_occurence` a consulta da mesma forma que foi preprocessado o texto do documento (use a classe `Cleaner` para isso). Este método irá retonar a consulta em um dicionario em que chave é o termo que ocorreu e o valor é uma instancia da classe TermOccurrence (ver Atividade 4). O doc_id deverá ser sempre None. Caso o termo nao exista no indice, ele será desconsiderado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta: crocodilo\n",
      "Resposta do método: {}\n",
      "\n",
      "Consulta: vocês\n",
      "Resposta do método: {'vocês': ( doc: None term_id:1 freq: 1)}\n",
      "\n",
      "Consulta: Vocês estejam\n",
      "Resposta do método: {'vocês': ( doc: None term_id:1 freq: 1), 'estejam': ( doc: None term_id:4 freq: 1)}\n",
      "\n",
      "Consulta: vocês vocês crocodilo\n",
      "Resposta do método: {'vocês': ( doc: None term_id:1 freq: 2)}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.101s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_get_query_term_occurence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 8 - Recuperação dos termos da consulta no índice:** O método `get_occurrence_list_per_term` possui com parametro a lista de termos da consulta. Este método retorna um dicionario com a lista de ocorrencia no indice de cada termo passado como parametro. Caso o termo não exista, este termo possuirá uma lista vazia. Veja o exemplo na atividade 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termos: ['crocodilo']\n",
      "Resposta do método: {'crocodilo': []}\n",
      "\n",
      "Termos: ['vocês', 'estejam', 'crocodilo']\n",
      "Resposta do método: {'vocês': [( doc: 2 term_id:1 freq: 3), ( doc: 3 term_id:1 freq: 1)], 'estejam': [( doc: 3 term_id:4 freq: 1)], 'crocodilo': []}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.096s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_get_occurence_list_per_term"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 9 - processamento da consulta:** Este método recebe como parametro a consulta, os valores precomputado do índice e o dicionário de documentos relevantes (extraídos do método `get_relevance_per_query`) para retornar uma lista de IDs ordenados de acordo com a consulta utilizando o modelo de ranking e indice que são os atributos `index` e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos dos documento da consulta 'crocodilo': {}\n",
      "\n",
      "Pesos dos documento da consulta 'vocês': {2: 0.40378886090583005, 3: 0.12190858668225728}\n",
      "\n",
      "Pesos dos documento da consulta 'Vocês estejam': {2: 0.40378886090583005, 3: 1.0168945556805116}\n",
      "\n",
      "Pesos dos documento da consulta 'vocês vocês crocodilo': {2: 0.8075777218116601, 3: 0.24381717336451456}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.101s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_get_docs_term"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 10: Método estático runQuery e criação da interface de caracteres - ou uso da interface gráfica/web:** Você deverá implementar o método `runQuery` que utilizando o indice, valores precomputados e o dicionario de indices relevantes irá fazer:\n",
    "\n",
    "- Instanciar um objeto de uma subclasse de RankingModel, de acordo com o que foi solicitado pelo usuário\n",
    "- Preprocessar os termos da consulta\n",
    "- Obter no indice as ocorrencias de cada termo do indice\n",
    "- Utilize o método get_docs_term para obter a lista de documentos que responde esta consulta\n",
    "- Caso seja uma consulta que possua documentos relevantes assinalados, fazer a avaliação da precisão e revocação dos top 10, 20 e 50\n",
    "- Imprimir as top 10 respostas. \n",
    "\n",
    "Caso  opte por fazer uma interface de web, você não precisará de fazer este método em especifico  - nem o `main`, explicado a seguir - , mas, deverá possibilitar o usuário entre com uma consulta e retorne as top 10 respostas além de imprimir a precisão e revocação dos top 10, 20 e 50 das consultas que possuem documentos relevantes assinalados. \n",
    "            \n",
    "Caso opte por implementar uma interface de carcteres você deverá terminar de implementar o método `main` para solicitar ao usuário a consulta e execute-a abaixo. Caso deseje, ao inves disso, você pode também fazer uma interface gráfica. Para testar este método, você deverá usar o indice da Wikipedia, assim, ele deve ser lido no início do programa. Você tem a liberdade de alterar este método como bem entender, mas lembre-se que os valores precomputados devem ser executado uma vez só durante a execução do programa antes da solicitação das consultas para que a consulta não fique lenta. Além disso, você deve ler o arquivo do índice também apenas uma vez (não indexe a Wikipedia novamente e sim leia o arquivo do indice gravado em memória). Caso deseje, você pode modificar o IndexPreComputedVals para armazenar mais elementos precomputados que facilitariam a consulta (ou a exibição da mesma). \n",
    "\n",
    "\n",
    "Para melhorar a apresentação, o arquivo `titlePerDoc.dat` apresenta o título do artigo por id do mesmo. Além disso, você deverá fazer uma análise e acordo com o [guia de escrita do relatório](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.bsvivts5y2ld) considerando as [tarefas do Trabalho Prático 3](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.fh1qug6oeoe7).\n",
    "\n",
    "\n",
    "Caso opte por fazer uma interface web, deve estar claro, neste Jupyter, as instruções para que seja possível executa-la, inclusive, as suas dependencias. Para melhoria de organização, a parte de interface grafica ou web deve ser feita em outros arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice lido com sucesso\n",
      "Precomputando valores atraves do indice...\n",
      "Precomputou valores done in 16.014716\n",
      "Cleaner instanciado com sucesso\n",
      "===========================================\n",
      "Fazendo query de 'belo horizonte'...\n",
      "Query Creation done in 0.0\n",
      "anwered with 1947 docs done in 0.014025\n",
      "Precisao @5: 0.0\n",
      "Recall @5: 0.0\n",
      "Precisao @10: 0.0\n",
      "Recall @10: 0.0\n",
      "Precisao @20: 0.0\n",
      "Recall @20: 0.0\n",
      "Precisao @50: 0.0\n",
      "Recall @50: 0.0\n",
      "Top 10:\n",
      "91853: Camargos\n",
      "93107: Rio Belo\n",
      "91856: Bairrocamargos\n",
      "32118: Capim Branco\n",
      "32436: Mateus Leme\n",
      "107302: Hélio Garcia\n",
      "105795: Aarão Reis\n",
      "32682: São Joaquim de Bicas\n",
      "32269: Florestal\n",
      "9931: Alto Horizonte\n",
      "Bottom 10:\n",
      "129883: John Milton\n",
      "103158: Identificação por radiofrequência\n",
      "97042: Correspondência de Fradique Mendes\n",
      "57536: Anura\n",
      "67161: Fídias\n",
      "12060: Língua turca\n",
      "56400: Ivã IV da Rússia\n",
      "49654: Fiódor Dostoiévski\n",
      "24618: Santiago de Compostela\n",
      "117527: Anarquismo individualista\n",
      "===========================================\n",
      "Fazendo query de 'Belo Horizonte'...\n",
      "Query Creation done in 0.0\n",
      "anwered with 1947 docs done in 0.004511\n",
      "Precisao @5: 0.0\n",
      "Recall @5: 0.0\n",
      "Precisao @10: 0.0\n",
      "Recall @10: 0.0\n",
      "Precisao @20: 0.0\n",
      "Recall @20: 0.0\n",
      "Precisao @50: 0.0\n",
      "Recall @50: 0.0\n",
      "Top 10:\n",
      "91853: Camargos\n",
      "93107: Rio Belo\n",
      "91856: Bairrocamargos\n",
      "32118: Capim Branco\n",
      "32436: Mateus Leme\n",
      "107302: Hélio Garcia\n",
      "105795: Aarão Reis\n",
      "32682: São Joaquim de Bicas\n",
      "32269: Florestal\n",
      "9931: Alto Horizonte\n",
      "Bottom 10:\n",
      "129883: John Milton\n",
      "103158: Identificação por radiofrequência\n",
      "97042: Correspondência de Fradique Mendes\n",
      "57536: Anura\n",
      "67161: Fídias\n",
      "12060: Língua turca\n",
      "56400: Ivã IV da Rússia\n",
      "49654: Fiódor Dostoiévski\n",
      "24618: Santiago de Compostela\n",
      "117527: Anarquismo individualista\n",
      "===========================================\n",
      "Fazendo query de 'Irlanda'...\n",
      "Query Creation done in 0.0\n",
      "anwered with 766 docs done in 0.002006\n",
      "Precisao @5: 0.0\n",
      "Recall @5: 0.0\n",
      "Precisao @10: 0.0\n",
      "Recall @10: 0.0\n",
      "Precisao @20: 0.0\n",
      "Recall @20: 0.0\n",
      "Precisao @50: 0.0\n",
      "Recall @50: 0.0\n",
      "Top 10:\n",
      "40089: Ilha da Irlanda\n",
      "39300: Cultura da Irlanda do Norte\n",
      "53322: Mar da Irlanda\n",
      "35401: Política da Irlanda do Norte\n",
      "11696: Bandeira da Irlanda do Norte\n",
      "43033: Subdivisões do Reino Unido\n",
      "131369: John Hume\n",
      "58189: Acordo de Belfast\n",
      "63292: Associação de Defesa do Ulster\n",
      "115901: Omagh\n",
      "Bottom 10:\n",
      "101785: Bismarck (couraçado)\n",
      "47637: Kendo\n",
      "108451: Segunda lei da termodinâmica\n",
      "41801: X-Men\n",
      "29856: Bielefeld\n",
      "117527: Anarquismo individualista\n",
      "100480: 24 (telessérie)\n",
      "24884: The Smashing Pumpkins\n",
      "338: Algarve\n",
      "59577: Percy Bysshe Shelley\n",
      "===========================================\n",
      "Fazendo query de 'Teste'...\n",
      "Query Creation done in 0.0\n",
      "anwered with 667 docs done in 0.001506\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'teste'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mquery\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m QueryRunner\n\u001b[1;32m----> 3\u001b[0m QueryRunner\u001b[39m.\u001b[39;49mmain()\n",
      "File \u001b[1;32mh:\\Github\\information-recovery\\ProcessamentoDeConsulta\\query\\processing.py:209\u001b[0m, in \u001b[0;36mQueryRunner.main\u001b[1;34m()\u001b[0m\n\u001b[0;32m    207\u001b[0m \tquery \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m  Digite a query: \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    208\u001b[0m \t\u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFazendo query de \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 209\u001b[0m result \u001b[39m=\u001b[39m QueryRunner\u001b[39m.\u001b[39;49mrunQuery(query, indexPreCom, index, cleaner, map_relevance)\n\u001b[0;32m    210\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTop 10:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m result[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32mh:\\Github\\information-recovery\\ProcessamentoDeConsulta\\query\\processing.py:147\u001b[0m, in \u001b[0;36mQueryRunner.runQuery\u001b[1;34m(query, indice_pre_computado, indice, cleaner, map_relevantes)\u001b[0m\n\u001b[0;32m    145\u001b[0m arr_precisao_revocao \u001b[39m=\u001b[39m []\n\u001b[0;32m    146\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 147\u001b[0m \tdoc_relervantes \u001b[39m=\u001b[39m map_relevantes[joined_query]\n\u001b[0;32m    148\u001b[0m \tarr_top \u001b[39m=\u001b[39m [\u001b[39m5\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m20\u001b[39m,\u001b[39m50\u001b[39m]\n\u001b[0;32m    149\u001b[0m \tprecisao \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'teste'"
     ]
    }
   ],
   "source": [
    "from query.processing import QueryRunner\n",
    "\n",
    "QueryRunner.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
