{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto você irá implementar o processamento de consultas. Nela, você utilizará o índice para retornar uma coleção ordenada e avaliação de algumas consultas selecionadas. Para isso, vocês deverão implementar alguns métodos das seguintes classes.\n",
    "\n",
    "- `IndexPreComputedVals`: Em alguns modelos, há a necessidade de processar alguns valores para que, no momento da execução da consulta, seja retornado de forma mais rápida. Esta classe analisa o índice e armazena informações necessárias para o calculo de cada tipo de modelagem;\n",
    "- `RankingModel`: Classe abstrata para a criação dos modelos. Ele possui o método `get_ordered_docs` a ser implementado por suas subclasses;\n",
    "- `BooleanRankingModel` Classe que retorna um resultado de consulta por meio do [modelo booleano](https://docs.google.com/presentation/d/1V62ll_IXRrsp6TYUHjx_T4jIyIc1ZVJYoOSwsxObybE/edit?usp=sharing)\n",
    "- `VectorRankingModel`: Classe que retorna um resultado de consulta por meio do [modelo vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing)\n",
    "- `QueryRunner`: Classe principal encarregada de obter a consulta e retornar os resultados;\n",
    "\n",
    "\n",
    "Este trabalho depende do código do indice (pacote `index`). Assim, você deve adicioná-o apropriadamente para dar continuidade ao projeto. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem Booleana e Vetorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 1 - Modelagem Booleana**: A abordagem booleana neste trabalho é simplificada. O modelo recebe o atributo `operator` que é uma instancia do [Enum](https://docs.python.org/3.4/library/enum.html) Operator. Caso o operador seja AND, será feito a operacao de interseção entre todos os documentos contidos ocorrencias de palavras, caso contrario, sendo OR, será feito a união. Exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Indexador.index.structure import TermOccurrence\n",
    "map_ocorrencias = {\"saturno\":[TermOccurrence(1,1,1),\n",
    "                            TermOccurrence(3,1,1)],\n",
    "                     \"plutao\":[TermOccurrence(2,5,1),\n",
    "                               TermOccurrence(4,5,1)],\n",
    "                        \"terra\":[TermOccurrence(1,2,1),\n",
    "                            TermOccurrence(2,2,1),\n",
    "                            TermOccurrence(4,2,1),],\n",
    "                        \"venus\":[TermOccurrence(1,3,1),\n",
    "                                TermOccurrence(2,3,1),\n",
    "                                TermOccurrence(3,3,1),\n",
    "                                TermOccurrence(4,3,1)],\n",
    "                        \"marte\":[TermOccurrence(1,4,2),\n",
    "                            TermOccurrence(3,4,1),\n",
    "                            TermOccurrence(4,4,1),],\n",
    "\n",
    "                        \"mercurio\":[TermOccurrence(3,6,1)]          \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1,2,3}|{2,4}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A intereseção entre `saturno` e `venus` resultará nos documentos 1 e 3 e, a união, nos documentos 1, 2, 3 e 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é uma forma bem simplificada para implementarmos o modelo booleano. Para isso, você deverá implementar os métodos `union_all` e `intersection_all` presentes na classe `BooleanRankingModel` no arquivo `ranking_models.py`. Esses métodos recebem como parâmetro um mapa com a lista de correncias de cada termo (similar a exemplificada acima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_boolean_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 2 - TF-IDF:** Agora, no mesmo arquivo, iremos finalizar a implementação do modelo Vetorial utilizando a classe `VectorRankingModel`. Nesta classe, primeiramente, você deverá implementar os [métodos estáticos](https://daniel-hasan.github.io/cefet-web-grad/classes/python2/) `tf`, `idf` e `tf_idf`. Sendo que $TF = 1+log_2(f_{ij})$ e $IDF_i = log_2(\\frac{N}{n_i})$ em que $f_{ij}$ é a frequência do termo $i$ no documento $j$, $N$ é o número de documentos e $n_i$ é o número de documentos que ocorrem o termo $i$. Abaixo, faça testes destes métodos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 6.906890595608519\n",
      "idf: 3.3219280948873626\n",
      "tf_idf: 22.94419391786525\n"
     ]
    }
   ],
   "source": [
    "from query.ranking_models import VectorRankingModel\n",
    "\n",
    "doc_count = 300\n",
    "term_frequency = 60\n",
    "doc_frequency = 30\n",
    "\n",
    "tf = VectorRankingModel.tf(term_frequency)\n",
    "idf = VectorRankingModel.idf(doc_count, doc_frequency)\n",
    "tf_idf = VectorRankingModel.tf_idf(doc_count, term_frequency, doc_frequency)\n",
    "\n",
    "print(f\"tf: {tf}\")\n",
    "print(f\"idf: {idf}\")\n",
    "print(f\"tf_idf: {tf_idf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3 - PreComputedVals:** No modelo vetorial temos que calcular a norma de cada documento $d_j$. Esse cálculo pode ser feito durante o preprocessamento da consulta. Assim, a classe `IndexPreComputedVals` possui o atributo `document_norm` que é um dicionário que mapeia cada documento $j$ à sua norma. Esse calculo é feito apenas uma vez ao iniciar o programa. \n",
    "\n",
    "Desta forma, você deverá terminar de implementar o método `precompute_vals` que percorre todo o índice e armazena a norma de cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.145s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_precomputed_vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 4 - Método `get_ordered_docs` da classe `VectorRankingModel`:** Usando os métodos implementados anteriormente você deverá ordenar os documentos contidos no mapa de ocorrencias `docs_occur_per_term` de acordo com a consulta `query` utilizando o modelo vetorial. O parametro `query` mapeia um termo presente na consulta, para a sua ocorrencia (objeto da classe `TermOcurrence`) na propria consulta. \n",
    "\n",
    "Para cada termo $t$ que ocorre na consulta, `docs_occur_per_term` mapeia cada termo com a lista de ocorrencias dele no índice. Veja abaixo um exemplo destes parametros usando a consulta `to be or not to be`.  Veja que, na consulta, `doc_id = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Indexador.index.structure import TermOccurrence\n",
    "query = {\n",
    "    \"to\":TermOccurrence(None, 1, 2),\n",
    "    \"be\":TermOccurrence(None, 2, 2),\n",
    "    \"or\":TermOccurrence(None, 3, 1),\n",
    "    \"not\":TermOccurrence(None, 4, 1),\n",
    "}\n",
    "\n",
    "docs_occur_per_term = {\n",
    "    \"to\":[TermOccurrence(1, 1, 4), TermOccurrence(2, 1, 1),],\n",
    "    \"be\":[TermOccurrence(1, 2, 1),TermOccurrence(2, 2, 1)],\n",
    "    \"or\":[TermOccurrence(2, 3, 1)],\n",
    "    \"not\":[TermOccurrence(3, 4, 1)],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, temos a consulta (representado pela variavel `query`) 'to to be be or not', ou seja, o `to` e o `be` ocorrendo duas vezes na consulta e, os demais termos, uma vez - a ordem não é definida no parametro. Em `docs_occcur_per_term` temos a ocorrencia desses termos nos documentos da coleção. \n",
    "\n",
    "Você deve executar o modelo vetorial para obter o resultado `documents_weight` que mapeia, para cada documento a similaridade entre ele e a consulta utilizando o modelo vetorial e a distancia do cosseno. Note que neste método você **não** pode navegar por todos os documentos da coleção pois, caso seja feito isso, o código de vocês iriam demorar muito caso sua coleção tiver milhões ou bilhões de documentos. Uma dica é usar o `documents_weight` para armazenar os valores intermediarios do somatorio de $w_{ij} \\times  w_{iq}$, tais variáveis são definidas nos [slides de modelagem vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing). \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse método retorna dois valores: (a) uma lista de ids de documentos ordenada de acordo com o modelo vetorial - use o método e um dicionário que mapeia, para cada documento, o seu peso. O método `rank_document_ids` será útil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_vector_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento da Consulta e Avaliação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora você irá fazer o processamento da consulta, informada pelo usuário, além de sua avaliação. A implementação do processamento de consultas será feito na classe `QueryRunner` do arquivo `processing.py`.\n",
    "\n",
    "**Requisito antes de começar:** o código que foi feito da indexação deve estar funcionando. Será utilizado a base de dados da Wikipédia. Você não deverá fazer a indexação toda quando iniciar o programa, ao invés disso, você deve persistir o indice todo em arquivo após a indexação. Usando FileIndex, como as ocorrencias já estão armazenadas em arquivo, você precisa armazenar apenas o conteúdo do `dic_index`. A [biblioteca json](https://docs.python.org/3/library/json.html) pode ajudar. Este índice será lido do arquivo apenas uma vez no início da execução do programa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criação da coleção de referência:** Para o projeto realizaremos uma avaliação bem simples, com o único intuito de simularmos um processo real de avaliação. Para tanto, consideraremos como conjunto de consultas de teste apenas três consultas:\n",
    "'Irlanda'\n",
    "'Belo Horizonte' e \n",
    "'São Paulo'\n",
    "\n",
    "O conjunto de documentos de teste compreenderá todas as páginas da base de dados da Wikipédia PT-BR utilizadas no projeto.  Para cada consulta, disponibilizamos um arquivo (na pasta `relevant_docs`) com o id de documentos relevantes (separados por vírgula) para as consultas teste.\n",
    "\n",
    "Por exemplo, um documento $D$ será considerado relevante para a consulta 'Belo Horizonte' somente \n",
    "se o id de $D$ estiver no arquivo `belo_horizonte.dat`. Você irá armazenar o conteúdo desses arquivos em memória para diminuir o tempo de busca. Feito isso, a coleção de referência para as três consultas estará montada e pode-se realizar os cálculos de avaliação corretamente.\n",
    "\n",
    "**Como um artigo foi considerado relevante para uma determinada consulta?** A Wikipedia organiza seus artigos em diversas categorias. Assim, para considerarmos se um artigo da Wikipédia é relevante, utilizamos essas categorias. Assim, para os documentos relevantes para a consulta 'Irlanda' (Arquivo `irlanda.dat`), foram considerados relevantes artigos da seguintes categorias: \n",
    " \n",
    "- Irlanda\n",
    "- Economia da Irlanda\n",
    "- História da Irlanda\n",
    "- Cultura da Irlanda\n",
    "- Romancistas da Irlanda\n",
    "- Físicos da Irlanda\n",
    "- Reis da Irlanda\n",
    "- Lordes da Irlanda\n",
    "\n",
    "Categorias relevantes para a consulta 'Belo Horizonte' (Arquivo `belo_horizonte.dat`): \n",
    "\n",
    "- Bairros de Belo Horizonte\n",
    "- Bandas de Belo Horizonte\n",
    "- Belo Horizonte\n",
    "- Edifícios de Belo Horizonte\n",
    "- Metrô de Belo Horizonte\n",
    "- Naturais de Belo Horizonte\n",
    "- Prefeitos de Belo Horizonte\n",
    "- Vereadores de Belo Horizonte\n",
    "\n",
    "Categorias relevantes para a consulta 'São Paulo' (arquivo `sao_paulo.dat`):\n",
    "\n",
    "- Atrações turísticas da cidade de São Paulo\n",
    "- Áreas protegidas de São Paulo\n",
    "- Prefeitos de São Paulo\n",
    "- São Paulo\n",
    "- Turismo em São Paulo\n",
    "- Universidades de São Paulo\n",
    "- Rodovias de São Paulo\n",
    "- Museus da cidade de São Paulo\n",
    "- Governadores de São Paulo\n",
    "- Municípios de São Paulo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 5 - Leitura dos arquivos de relevâncias:** Você deverá implementar o método `get_relevance_per_query` que irá ler todos os arquivo da pasta `relevant_docs` e, com isso, retornar um mapeamento em que a chave é a string de consulta e o valor é o **conjunto** de ids de documentos. Veja um exemplo de retorno com as consultas `Bolívia`, `Brasil` e `Porto Seguro`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retorno = {\"Bolívia\":{1,3,5,6,233},\n",
    "            \"Brasil\":{2,4,5,3},\n",
    "           \"Porto Seguro\":{3,43,21,3,12,233}\n",
    "          }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça um teste de execução abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'belo_horizonte': {'97000', '43658', '69168', '80198', '125549', '101043', '35985', '136473\\n', '49186', '110030', '136473', '1083', '484', '91853', '106575', '108604', '91593', '104137', '40226', '49772', '29241', '18111', '38636', '107302', '130173', '19588', '47967'}, 'irlanda': {'7765', '1393', '53004', '51714', '37632', '51778', '33833', '1034', '51786', '95773', '51716', '3765', '45577', '11953', '9955', '124818\\n', '9918', '26276', '44259', '13256', '15393', '52995', '54836', '51779', '111966', '105145', '83228', '58189', '47185', '39300', '93223', '105348', '1196', '37935', '52998', '46441', '39049', '43872', '102888'}, 'sao_paulo': {'49752', '35064', '24007', '41967', '68791', '35193', '23439', '37255', '37261', '34950', '125876', '35029', '34879', '34858', '67967', '34923', '35212', '35194', '34815', '128635', '32573', '35138', '35181', '30640', '63586', '18307', '34779', '34981', '35077', '34821', '34807', '34814', '35173', '34812', '35145', '35126', '35114', '130537', '35216', '34894', '115341', '17768', '27897', '120283', '35875', '34985', '35198', '37241', '34871', '67685', '34896', '121025', '124032', '34806', '35206', '34855', '99800', '70457', '35093', '35165', '35100', '120284', '37265', '35076', '34970', '34968', '35067', '35122', '10792', '34794', '35052', '35238', '34986', '107278', '44836', '18305', '34921', '64326', '34777', '34787', '359', '34851', '103003', '120839', '70209', '35151', '18364', '63617', '34819', '47240', '52391', '35087', '105369', '36511', '34999', '32353', '96944', '96952', '34808', '34984', '37240', '67965', '34876', '35110', '23402', '7687', '34908', '105368', '35036', '34891', '103495', '34809', '18482', '71322', '121946', '35049', '35102', '17703', '43939', '35011', '35115', '35141', '35218', '34884', '30402', '63702', '33643', '30667', '95286', '35222', '103736', '35171', '84257', '34825', '1084', '124692', '34963', '35074', '63715', '33530', '112599', '16865', '820', '35020', '34911', '104847', '34850', '35066', '34992', '41964', '35123', '34928', '41945', '35086', '34830', '107604', '34861', '36238', '101163', '41761', '37274', '34978', '35108', '35239', '35161', '35079', '34918', '63637', '106867', '54205', '33739', '35229', '30119', '107841', '35144', '34798', '23505', '35135', '58105', '34962', '64679', '34786', '35210', '34983', '35233', '44033', '34843', '34874', '12381', '34893', '34791', '34931', '41948', '1719', '11478', '63593', '34965', '123706', '35148', '63613', '34824', '34885', '35001', '35007', '64908', '65568', '117875', '35164', '35061', '35143', '34869', '37249', '67061', '37258', '3546', '49745', '15814', '35089', '34878', '35134', '34849', '30016', '35241', '37054', '128906', '34898', '34919', '34936', '35197', '35160', '37243', '34991', '127538', '37242', '35012', '9744', '110028', '116539', '34892', '30658', '34882', '35223', '118365', '35167', '34940', '35230', '35117', '19963', '117951', '135137\\n', '34971', '71920', '35058', '34699', '35184', '35124', '57810', '35069', '26805', '62759', '64678', '35054', '77762', '42765', '35111', '35073', '50674', '29459', '23412', '34868', '33850', '37087', '34770', '103262', '35217', '132004', '125623', '52388', '41955', '34926', '18769', '44596', '41961', '123161', '22647', '34903', '35119', '24088', '35125', '96931', '124892', '67301', '130272', '34937', '23988', '35101', '111222', '37256', '35168', '35231', '129465', '30654', '34974', '37283', '23441', '56310', '35140', '35205', '35157', '34943', '35023', '34930', '123768', '35156', '63584', '34862', '35028', '121580', '29477', '35055', '35153', '34914', '37244', '60431', '34915', '34776', '113733', '18285', '53155', '35026', '37247', '116543', '38535', '34872', '35155', '30653', '35139', '34837', '18411', '34844', '44001', '35095', '35188', '23990', '111495', '21467', '37056', '25107', '35043', '54428', '37053', '66592', '37297', '35213', '34880', '55965', '33267', '23420', '34902', '37252', '34784', '35177', '35098', '34959', '61403', '34863', '35039', '35030', '31889', '127303', '110131', '100337', '110916', '46533', '35170', '34865', '62828', '35046', '34932', '17422', '110315', '34613', '29427', '34953', '54087', '18299', '11664', '35027', '34967', '34836', '10756', '34606', '35000', '34934', '24089', '34935', '71562', '56690', '34995', '34958', '35227', '35226', '34987', '31888', '31879', '35022', '47510', '117843', '17661', '34969', '35038', '35047', '37600', '34900', '34945', '58490', '94770', '44043', '35040', '124267', '40127', '34627', '53269', '35132', '9928', '34803', '34653', '34888', '35207', '34886', '12383', '34847', '114625', '128145', '34820', '31880', '35130', '35202', '34773', '35021', '30649', '23983', '8170', '61190', '34982', '35182', '130359', '131865', '35083', '108256', '34857', '31882', '34901', '45081', '114888', '35158', '35113', '63776', '76506', '35034', '37085', '35189', '47221', '35004', '34933', '59093', '35032', '30652', '108677', '35174', '35195', '104490', '34939', '35215', '115646', '35112', '727', '35131', '31890', '34897', '31886', '18312', '35041', '105372', '35163', '34873', '35048', '35224', '35092', '35186', '34912', '44027', '125486', '29476', '120924', '34845', '35149', '30669', '74190', '1752', '35183', '35235', '71254', '22159', '31202', '34778', '63827', '78269', '35024', '34990', '27860', '23413', '72332', '29460', '34832', '42255', '60430', '35006', '35204', '9277', '9258', '10558', '35166', '63775', '35175', '78432', '35221', '18143', '34907', '7847', '1324', '126579', '42582', '132760', '62764', '35056', '34841', '34979', '34822', '120719', '35201', '41942', '1291', '96945', '34890', '35214', '24546', '72497', '35150', '53833', '13726', '34800', '34840', '35099', '41906', '34952', '34998', '34785', '36655', '26173', '35063', '63123', '37282', '18515', '35240', '35031', '35225', '91915', '132679', '18489', '35059', '58426', '34852', '41958', '114091', '45239', '98274', '41944', '30641', '15837', '21504', '34813', '35162', '60377', '35002', '34906', '52221', '34831', '34975', '35196', '32738', '16722', '50702', '35109', '113999', '34829', '35035', '34895', '34941', '83535', '41971', '34972', '34955', '35070', '12218'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.124s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_get_relevance_per_query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 6 - count_top_n_relevant:** Um método que auxilirará vocês na avaliação é o método count_top_n_relevant da classe Query Runner.  Esse método calcula a quantidade de documentos relevantes nas top `n` posições da lista `lstResposta` que é a resposta a uma consulta - lista de ids de documentos. `lstResposta` será a lista de respostas ordenadas por um método de processamento de consulta (BM25, Modelo vetorial). Os ids de documentos relevantes estão no parametro `docRelevantes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.165s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.processing ProcessingTest.test_count_top_n_relevant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 7 - processamento da consulta**: O método `get_query_term_occurence` a consulta da mesma forma que foi preprocessado o texto do documento (use a classe `Cleaner` para isso). Este método irá retonar a consulta em um dicionario em que chave é o termo que ocorreu e o valor é uma instancia da classe TermOccurrence (ver Atividade 4). O doc_id deverá ser sempre None. Caso o termo nao exista no indice, ele será desconsiderado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_query_term_occurence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 8 - Recuperação dos termos da consulta no índice:** O método `get_occurrence_list_per_term` possui com parametro a lista de termos da consulta. Este método retorna um dicionario com a lista de ocorrencia no indice de cada termo passado como parametro. Caso o termo não exista, este termo possuirá uma lista vazia. Veja o exemplo na atividade 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_occurence_list_per_term"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 9 - processamento da consulta:** Este método recebe como parametro a consulta, os valores precomputado do índice e o dicionário de documentos relevantes (extraídos do método `get_relevance_per_query`) para retornar uma lista de IDs ordenados de acordo com a consulta utilizando o modelo de ranking e indice que são os atributos `index` e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_docs_term"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 10: Método estático runQuery e criação da interface de caracteres - ou uso da interface gráfica/web:** Você deverá implementar o método `runQuery` que utilizando o indice, valores precomputados e o dicionario de indices relevantes irá fazer:\n",
    "\n",
    "- Instanciar um objeto de uma subclasse de RankingModel, de acordo com o que foi solicitado pelo usuário\n",
    "- Preprocessar os termos da consulta\n",
    "- Obter no indice as ocorrencias de cada termo do indice\n",
    "- Utilize o método get_docs_term para obter a lista de documentos que responde esta consulta\n",
    "- Caso seja uma consulta que possua documentos relevantes assinalados, fazer a avaliação da precisão e revocação dos top 10, 20 e 50\n",
    "- Imprimir as top 10 respostas. \n",
    "\n",
    "Caso  opte por fazer uma interface de web, você não precisará de fazer este método em especifico  - nem o `main`, explicado a seguir - , mas, deverá possibilitar o usuário entre com uma consulta e retorne as top 10 respostas além de imprimir a precisão e revocação dos top 10, 20 e 50 das consultas que possuem documentos relevantes assinalados. \n",
    "            \n",
    "Caso opte por implementar uma interface de carcteres você deverá terminar de implementar o método `main` para solicitar ao usuário a consulta e execute-a abaixo. Caso deseje, ao inves disso, você pode também fazer uma interface gráfica. Para testar este método, você deverá usar o indice da Wikipedia, assim, ele deve ser lido no início do programa. Você tem a liberdade de alterar este método como bem entender, mas lembre-se que os valores precomputados devem ser executado uma vez só durante a execução do programa antes da solicitação das consultas para que a consulta não fique lenta. Além disso, você deve ler o arquivo do índice também apenas uma vez (não indexe a Wikipedia novamente e sim leia o arquivo do indice gravado em memória). Caso deseje, você pode modificar o IndexPreComputedVals para armazenar mais elementos precomputados que facilitariam a consulta (ou a exibição da mesma). \n",
    "\n",
    "\n",
    "Para melhorar a apresentação, o arquivo `titlePerDoc.dat` apresenta o título do artigo por id do mesmo. Além disso, você deverá fazer uma análise e acordo com o [guia de escrita do relatório](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.bsvivts5y2ld) considerando as [tarefas do Trabalho Prático 3](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.fh1qug6oeoe7).\n",
    "\n",
    "\n",
    "Caso opte por fazer uma interface web, deve estar claro, neste Jupyter, as instruções para que seja possível executa-la, inclusive, as suas dependencias. Para melhoria de organização, a parte de interface grafica ou web deve ser feita em outros arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
